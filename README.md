# MultiArmedBandits
Python implementation of Multi armed bandits, with agent classes and arms for rapid experimentation. Mostly fun!

Check notebook [here](https://nbviewer.jupyter.org/github/arjunbazinga/MultiArmedBandits/blob/master/Multi-Armed-Bandits.ipynb)
